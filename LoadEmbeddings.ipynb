{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LoadEmbeddings.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOkFk/BAgYpX9loZ3yANu7P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This part has been done separately due to the file size.\n","The embeddings file can be downloaded from here:\n","https://github.com/mmihaltz/word2vec-GoogleNews-vectors"],"metadata":{"id":"WnJYeo-8L2hi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZYoO66oLxry"},"outputs":[],"source":["import nltk\n","from gensim.models import KeyedVectors\n","import gzip\n","import pandas as pd\n","import pickle"]},{"cell_type":"code","source":["# load embeddings\n","embeddings = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary = True)\n","# get a set of relevant words\n","words = pd.read_csv('words.csv')\n","set_words = set(words.word)"],"metadata":{"id":"IizDzRAmL8yi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_word_embeddings(embeddings):\n","\n","    word_embeddings = {}\n","    for word in embeddings.key_to_index:\n","        if word in set_words:\n","            word_embeddings[word] = embeddings[word]\n","    return word_embeddings\n"],"metadata":{"id":"jOa8-_SJL_ye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Testing your function\n","word_embeddings = get_word_embeddings(embeddings)\n","print(len(word_embeddings))\n","pickle.dump( word_embeddings, open( \"word_embeddings_subset.p\", \"wb\" ) )"],"metadata":{"id":"dTDlYBEAMBVe"},"execution_count":null,"outputs":[]}]}